{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 다운로드\n",
    "(X_train, _y_train), (X_test, _y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정리\n",
    "N = 10000\n",
    "\n",
    "X_train = X_train[:N * 4 // 5]\n",
    "_y_train = _y_train[:N * 4 // 5]\n",
    "X_test = X_test[:N * 1 // 5]\n",
    "_y_test = _y_test[:N * 1 // 5]\n",
    "\n",
    "X_train, X_test =\\\n",
    "    np.reshape(X_train, (X_train.shape[0], -1)),\\\n",
    "    np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "y_train = np.zeros((len(_y_train), 10))\n",
    "y_train[np.arange(len(_y_train)), _y_train] = 1\n",
    "\n",
    "y_test = np.zeros((len(_y_test), 10))\n",
    "y_test[np.arange(len(_y_test)), _y_test] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "n_in = len(X_train[0])\n",
    "n_hidden = 200\n",
    "n_out = 10\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(n_hidden, input_dim=n_in),\n",
    "    Activation('relu'),\n",
    "    Dense(n_hidden),\n",
    "    Activation('relu'),\n",
    "    Dense(n_hidden),\n",
    "    Activation('relu'),\n",
    "    Dense(n_out),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 14.2149 - acc: 0.1154\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 13.2559 - acc: 0.1759\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 11.6509 - acc: 0.2745\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 10.8914 - acc: 0.3206\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 10.3205 - acc: 0.3566\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 9.6816 - acc: 0.3936\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 9.0320 - acc: 0.4340\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 8.4589 - acc: 0.4674\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 7.6323 - acc: 0.5183\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 7.1844 - acc: 0.5463\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 6.0771 - acc: 0.6139\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 5.2435 - acc: 0.6642\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4.2197 - acc: 0.7310\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 4.0198 - acc: 0.7431\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3.9847 - acc: 0.7465\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 3.7876 - acc: 0.7551\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 2.6420 - acc: 0.8265\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 2.4057 - acc: 0.8386\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 2.1933 - acc: 0.8565\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 2.1845 - acc: 0.8566\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 2.0756 - acc: 0.8645\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 2.0369 - acc: 0.8675\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1.9516 - acc: 0.8733\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 1.9210 - acc: 0.8767\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 1.7330 - acc: 0.8855\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.9207 - acc: 0.9332\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.6072 - acc: 0.9536\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.5209 - acc: 0.9605\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.4390 - acc: 0.9655\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3939 - acc: 0.9705\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3520 - acc: 0.9734\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3030 - acc: 0.9773\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2704 - acc: 0.9809\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2687 - acc: 0.9794\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.2406 - acc: 0.9825\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.2486 - acc: 0.9819\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2146 - acc: 0.9844\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.2176 - acc: 0.9844\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.1870 - acc: 0.9873\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.1852 - acc: 0.9876\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.1818 - acc: 0.9875\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.1696 - acc: 0.9890\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.1632 - acc: 0.9899\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.1632 - acc: 0.9899\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.1632 - acc: 0.9899\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.1632 - acc: 0.9899\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.1632 - acc: 0.9899\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.1632 - acc: 0.9899\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.1632 - acc: 0.9899\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1632 - acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1207a2160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 108us/step\n",
      "[1.0361718957019048, 0.92]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "loss_and_metrics = model.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
